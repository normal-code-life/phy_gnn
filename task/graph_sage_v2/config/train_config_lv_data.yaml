task_base:
  task_name: graph_sage_v2
  exp_name: 30
  overwrite_exp_folder: True
  gpu: True
  cuda_core: "cuda:0"
task_data:
  task_data_name: lvData
  edge_indices_generate_method: 2
  n_shape_coeff: 32  # Number of shape coefficients to input to the emulator
task_trainer:
  model_name: GraphSAGEModel
  epochs: 15000
  optimizer_param:
    name: adam
    learning_rate: 0.00005  # Learning rate for training the network
  loss_param:
    name: euclidean_distance_mse
  metrics_param:
    - mean_absolute_error
    # - explained_va/riance
  callback_param:
    tensorboard:
#      log_dir: "./"
      profiler : False
    model_checkpoint:
      save_freq: 500
    logs:
      update_freq: 1
      save_task_code: True
  dataset_param:
    batch_size: 1
    val_batch_size: 10
    num_workers: 5
    prefetch_factor: 1
    val_prefetch_factor: 10
  static_graph: False
task_train:
  neighbour_layers: 1
  node_input_mlp_layer:
    unit_sizes: [13, 128, 128, 40]
    layer_norm: True
    activation: tanh
  edge_input_mlp_layer:
    unit_sizes: [29, 128, 128, 40]
    layer_norm: True
    activation: tanh
  message_passing_layer:
    agg_method: SUMAggregator
    layer_threshold: [50, 200, 500, 1000, 6700]
    layer_selected_node_num: [12, 12, 12, 12, 12]
    agg_layer:
      agg_dim: 2
      keep_dim: False
    node_mlp_layer:
      unit_sizes: [80, 128, 128, 40]
      layer_norm: True
      activation: tanh
    edge_mlp_layer:
      unit_sizes: [89, 128, 128, 40]
      layer_norm: True
      activation: tanh
  theta_input_mlp_layer:
    unit_sizes: [4, 128, 128, 40]
    layer_norm: True
    activation: tanh
  decoder_layer:
    unit_sizes: [112, 128, 128, 1]
    layer_norm: False
    activation: tanh
    output_dim: 3
